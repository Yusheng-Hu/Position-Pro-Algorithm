name: Python Iter Performance Bench

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:

# Disable automatic cancellation to ensure all queued benchmarks complete
concurrency:
  group: global-readme-sync
  cancel-in-progress: false

permissions:
  contents: write

jobs:
  python-bench:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up PyPy 3.10
      uses: actions/setup-python@v5
      with:
        python-version: 'pypy-3.10'

    - name: Run Benchmark and Generate Content
      id: bench_step
      run: |
        cd python
        # 1. Capture hardware and time
        CPU_MODEL=$(grep -m 1 "model name" /proc/cpuinfo | cut -d: -f2 | sed 's/^[ \t]*//')
        TIME_UTC=$(date -u +"%a %b %d %H:%M:%S %Y UTC")
        TIME_BJ=$(TZ=Asia/Shanghai date +"%a %b %d %H:%M:%S %Y (UTC+8)")
        
        # 2. Run the actual script
        python pp_iter.py > raw_data.log
        
        # 3. Use a robust Python block to build the Markdown table
        # This handles any whitespace issues in the raw_data.log
        python3 -c "
        import os
        
        header = '#### Last Automated Run: $TIME_UTC / $TIME_BJ\n'
        env_info = '**Environment: $CPU_MODEL (GitHub Actions Runner)**\n\n'
        table_header = '| N | Total Permutations | Itertools (s) | Position Pure (s) | Speed-up |\n|---|---|---|---|---|\n'
        
        table_rows = []
        if os.path.exists('raw_data.log'):
            with open('raw_data.log', 'r') as f:
                for line in f:
                    # Strip and split by any whitespace
                    parts = line.strip().split()
                    # Ensure we have the 5 expected columns (N, Total, Iter, PP, Speed)
                    if len(parts) >= 5:
                        row = f'| {parts[0]} | {parts[1]} | {parts[2]} | {parts[3]} | {parts[4]} |'
                        table_rows.append(row)
        
        final_output = header + env_info + table_header + '\n'.join(table_rows)
        with open('bench_formatted.md', 'w', encoding='utf-8') as f:
            f.write(final_output)
        "
        cat bench_formatted.md >> $GITHUB_STEP_SUMMARY

    - name: Inject into README.md
      shell: python
      run: |
        import os, sys
        start_m = "[//]: # (PYTHON_PP_ITER_BENCHMARK_START)"
        end_m = "[//]: # (PYTHON_PP_ITER_BENCHMARK_END)"
        
        # Read formatted result from the python directory
        with open("python/bench_formatted.md", "r", encoding="utf-8") as f:
            new_table_content = f.read().strip()
            
        with open("README.md", "r", encoding="utf-8") as f:
            readme = f.read()

        if start_m in readme and end_m in readme:
            before = readme.split(start_m)[0]
            after = readme.split(end_m)[1]
            # Construct final section
            section = f"### üêç Position Pure Iterator Performance (PyPy)\n\n{new_table_content}"
            new_readme = f"{before}{start_m}\n\n{section}\n\n{end_m}{after}"
            with open("README.md", "w", encoding="utf-8") as f:
                f.write(new_readme)
        else:
            print("Error: Markers not found in README.md")
            sys.exit(1)

    - name: Synchronized Git Push
      run: |
        git config --global user.name "github-actions[bot]"
        git config --global user.email "github-actions[bot]@users.noreply.github.com"
        
        for i in {1..5}; do
          git add README.md
          if git commit -m "docs: fix python benchmark table formatting [skip ci]"; then
            git pull --rebase origin main
            if git push; then exit 0; fi
          else
            echo "No changes to commit"
            exit 0
          fi
          sleep 5
        done
        exit 1
